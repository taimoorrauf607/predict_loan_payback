{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62329a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a73ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59c2e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['annual_income', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate']\n",
    "df[num_cols] = df[num_cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1d6d955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "annual_income           1.719509\n",
       "debt_to_income_ratio    1.406680\n",
       "credit_score           -0.166993\n",
       "loan_amount             0.207360\n",
       "interest_rate           0.049945\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[num_cols].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "527d9d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log transformation to reduce skewness\n",
    "#these columns are right skewed\n",
    "df['annual_income_log'] = np.log1p(df['annual_income'])\n",
    "df['dti_log'] = np.log1p(df['debt_to_income_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ee88c",
   "metadata": {},
   "source": [
    "## Feature ENgineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf1b5e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['income_loan_ratio'] = df['annual_income'] / (df['loan_amount'] + 1)\n",
    "df['payment_burden'] = (df['loan_amount'] * df['interest_rate']) / (df['annual_income'] + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be0277d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def credit_bucket(x):\n",
    "    if x >= 750: return \"Excellent\"\n",
    "    elif x >= 700: return \"Good\"\n",
    "    elif x >= 650: return \"Fair\"\n",
    "    else: return \"Poor\"\n",
    "\n",
    "df['credit_bucket'] = df['credit_score'].apply(credit_bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "639394de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['credit_score_sq'] = df['credit_score'] ** 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ba0657",
   "metadata": {},
   "source": [
    "### 4. Categorical Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ed3b145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 593994 entries, 0 to 593993\n",
      "Data columns (total 23 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   id                    593994 non-null  int64  \n",
      " 1   annual_income         593994 non-null  float64\n",
      " 2   debt_to_income_ratio  593994 non-null  float64\n",
      " 3   credit_score          593994 non-null  int64  \n",
      " 4   loan_amount           593994 non-null  float64\n",
      " 5   interest_rate         593994 non-null  float64\n",
      " 6   gender                593994 non-null  object \n",
      " 7   marital_status        593994 non-null  object \n",
      " 8   education_level       593994 non-null  object \n",
      " 9   employment_status     593994 non-null  object \n",
      " 10  loan_purpose          593994 non-null  object \n",
      " 11  grade_subgrade        593994 non-null  object \n",
      " 12  loan_paid_back        593994 non-null  float64\n",
      " 13  annual_income_log     593994 non-null  float64\n",
      " 14  dti_log               593994 non-null  float64\n",
      " 15  income_loan_ratio     593994 non-null  float64\n",
      " 16  payment_burden        593994 non-null  float64\n",
      " 17  credit_bucket         593994 non-null  object \n",
      " 18  credit_score_sq       593994 non-null  int64  \n",
      " 19  grade                 593994 non-null  object \n",
      " 20  subgrade_num          593994 non-null  int64  \n",
      " 21  grade_num             593994 non-null  int64  \n",
      " 22  grade_full_num        593994 non-null  int64  \n",
      "dtypes: float64(9), int64(6), object(8)\n",
      "memory usage: 104.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12d369fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_paid_back\n",
       "1.0    474494\n",
       "0.0    119500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['loan_paid_back'].value_counts()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8040963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert letter-grade to numeric ranking\n",
    "df['grade'] = df['grade_subgrade'].str[0]\n",
    "df['subgrade_num'] = df['grade_subgrade'].str[1:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "965ba152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 1. Ordinal Encoding\n",
    "df['education_rank'] = df['education_level'].map({\n",
    "    \"PhD\":4, \"Master's\":3, \"Bachelor's\":2, \"High School\":1, \"Other\":0\n",
    "})\n",
    "\n",
    "df['credit_bucket_rank'] = df['credit_bucket'].map({\n",
    "    \"Excellent\":4, \"Good\":3, \"Fair\":2, \"Poor\":1\n",
    "})\n",
    "\n",
    "# 2. Target Encoding function\n",
    "def target_encode(train, col, target='loan_paid_back'):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    global_mean = train[target].mean()\n",
    "    te = pd.Series(index=train.index, dtype=float)\n",
    "\n",
    "    for tr_idx, val_idx in kf.split(train):\n",
    "        train_fold = train.iloc[tr_idx]\n",
    "        val_fold = train.iloc[val_idx]\n",
    "        mapping = train_fold.groupby(col)[target].mean()\n",
    "        te.iloc[val_idx] = val_fold[col].map(mapping).fillna(global_mean)\n",
    "    return te\n",
    "\n",
    "# Target encoding\n",
    "df['grade_te'] = target_encode(df, 'grade')\n",
    "df['loan_purpose_te'] = target_encode(df, 'loan_purpose')\n",
    "df['employment_status_te'] = target_encode(df, 'employment_status')\n",
    "\n",
    "# 3. One-hot encoding\n",
    "df = pd.get_dummies(df, columns=['gender','marital_status'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e37b9409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>debt_to_income_ratio</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>grade_subgrade</th>\n",
       "      <th>loan_paid_back</th>\n",
       "      <th>annual_income_log</th>\n",
       "      <th>dti_log</th>\n",
       "      <th>...</th>\n",
       "      <th>education_rank</th>\n",
       "      <th>credit_bucket_rank</th>\n",
       "      <th>grade_te</th>\n",
       "      <th>loan_purpose_te</th>\n",
       "      <th>employment_status_te</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_Other</th>\n",
       "      <th>marital_status_Married</th>\n",
       "      <th>marital_status_Single</th>\n",
       "      <th>marital_status_Widowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29367.99</td>\n",
       "      <td>0.084</td>\n",
       "      <td>736</td>\n",
       "      <td>2528.42</td>\n",
       "      <td>13.67</td>\n",
       "      <td>C3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.287695</td>\n",
       "      <td>0.080658</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.847562</td>\n",
       "      <td>0.802012</td>\n",
       "      <td>0.899948</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22108.02</td>\n",
       "      <td>0.166</td>\n",
       "      <td>636</td>\n",
       "      <td>4593.10</td>\n",
       "      <td>12.92</td>\n",
       "      <td>D3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.003741</td>\n",
       "      <td>0.153579</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.715457</td>\n",
       "      <td>0.796389</td>\n",
       "      <td>0.894201</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49566.20</td>\n",
       "      <td>0.097</td>\n",
       "      <td>694</td>\n",
       "      <td>17005.15</td>\n",
       "      <td>9.76</td>\n",
       "      <td>C5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.811085</td>\n",
       "      <td>0.092579</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.847562</td>\n",
       "      <td>0.797286</td>\n",
       "      <td>0.894132</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46858.25</td>\n",
       "      <td>0.065</td>\n",
       "      <td>533</td>\n",
       "      <td>4682.48</td>\n",
       "      <td>16.10</td>\n",
       "      <td>F1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.754904</td>\n",
       "      <td>0.062975</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.626994</td>\n",
       "      <td>0.797795</td>\n",
       "      <td>0.894269</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>25496.70</td>\n",
       "      <td>0.053</td>\n",
       "      <td>665</td>\n",
       "      <td>12184.43</td>\n",
       "      <td>10.21</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.146344</td>\n",
       "      <td>0.051643</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.715457</td>\n",
       "      <td>0.802117</td>\n",
       "      <td>0.894201</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  annual_income  debt_to_income_ratio  credit_score  loan_amount  \\\n",
       "0   0       29367.99                 0.084           736      2528.42   \n",
       "1   1       22108.02                 0.166           636      4593.10   \n",
       "2   2       49566.20                 0.097           694     17005.15   \n",
       "3   3       46858.25                 0.065           533      4682.48   \n",
       "4   4       25496.70                 0.053           665     12184.43   \n",
       "\n",
       "   interest_rate grade_subgrade  loan_paid_back  annual_income_log   dti_log  \\\n",
       "0          13.67             C3             1.0          10.287695  0.080658   \n",
       "1          12.92             D3             0.0          10.003741  0.153579   \n",
       "2           9.76             C5             1.0          10.811085  0.092579   \n",
       "3          16.10             F1             1.0          10.754904  0.062975   \n",
       "4          10.21             D1             1.0          10.146344  0.051643   \n",
       "\n",
       "   ...  education_rank  credit_bucket_rank  grade_te  loan_purpose_te  \\\n",
       "0  ...               1                   3  0.847562         0.802012   \n",
       "1  ...               3                   1  0.715457         0.796389   \n",
       "2  ...               1                   2  0.847562         0.797286   \n",
       "3  ...               1                   1  0.626994         0.797795   \n",
       "4  ...               1                   2  0.715457         0.802117   \n",
       "\n",
       "   employment_status_te  gender_Male  gender_Other  marital_status_Married  \\\n",
       "0              0.899948        False         False                   False   \n",
       "1              0.894201         True         False                    True   \n",
       "2              0.894132         True         False                   False   \n",
       "3              0.894269        False         False                   False   \n",
       "4              0.894201         True         False                    True   \n",
       "\n",
       "   marital_status_Single  marital_status_Widowed  \n",
       "0                   True                   False  \n",
       "1                  False                   False  \n",
       "2                   True                   False  \n",
       "3                   True                   False  \n",
       "4                  False                   False  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04696c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original categorical columns\n",
    "df.drop(columns=['loan_purpose','employment_status','grade','education_level','credit_bucket'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c06f886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 5) Additional engineered numeric features (as previously suggested)\n",
    "# ---------------------------\n",
    "df['income_loan_ratio'] = df['annual_income'] / (df['loan_amount'] + 1)\n",
    "df['payment_burden'] = (df['loan_amount'] * df['interest_rate']) / (df['annual_income'] + 1)\n",
    "df['credit_x_dti'] = df['credit_score'] * df['debt_to_income_ratio']\n",
    "df['loan_x_rate'] = df['loan_amount'] * df['interest_rate']\n",
    "\n",
    "engineered_numeric = ['income_loan_ratio', 'payment_burden', 'credit_x_dti', 'loan_x_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12b9c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_extended=['annual_income_log', 'dti_log', 'credit_score', 'loan_amount', 'interest_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6e0fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['annual_income', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa2595b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_training_pipeline.py\n",
    "import os\n",
    "import random\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "# import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8f21d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14fa4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 6) Feature list for modeling\n",
    "# ---------------------------\n",
    "features = (num_cols_extended +\n",
    "            ['education_rank', 'credit_bucket_rank', 'grade_rank'] +\n",
    "            [c for c in df.columns if c.endswith('_te')] +   # all TE features\n",
    "            ['gender_Male','gender_Other'] if 'gender_Male' in df.columns else []  # include dummies if exist\n",
    "           )\n",
    "# Add marital dummies if present\n",
    "marital_cols = [c for c in df.columns if c.startswith('marital_status_')]\n",
    "features += marital_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8bcec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_numeric = ['income_loan_ratio', 'payment_burden', 'credit_x_dti', 'loan_x_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09229bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features += engineered_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "354f86c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute numeric missing values if any (median)\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "df[num_cols_extended] = num_imputer.fit_transform(df[num_cols_extended])\n",
    "# Impute any produced NaN/inf\n",
    "df[engineered_numeric] = df[engineered_numeric].replace([np.inf, -np.inf], np.nan)\n",
    "# df[engineered_numeric] = num_imputer.transform(df[engineered_numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be38e44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 20\n",
      "Final features used: ['annual_income_log', 'dti_log', 'credit_score', 'loan_amount', 'interest_rate', 'education_rank', 'credit_bucket_rank', 'grade_te', 'loan_purpose_te', 'employment_status_te', 'gender_Male', 'gender_Other', 'marital_status_Married', 'marital_status_Single', 'marital_status_Widowed', 'income_loan_ratio', 'payment_burden', 'credit_x_dti', 'loan_x_rate']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.joblib']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure unique\n",
    "features = [f for i,f in enumerate(features) if f not in features[:i]]\n",
    "print(\"Number of features:\", len(features))\n",
    "\n",
    "# If any features missing (dummy variable absence), build from available list\n",
    "features = [f for f in features if f in df.columns]\n",
    "print(\"Final features used:\", features)\n",
    "\n",
    "# Standard scaling numeric features for XGBoost (optional for LightGBM not necessary but okay)\n",
    "scaler = StandardScaler()\n",
    "scale_cols = [c for c in features if c in num_cols_extended + engineered_numeric + ['education_rank','credit_bucket_rank','grade_rank']]\n",
    "df[scale_cols] = scaler.fit_transform(df[scale_cols])\n",
    "\n",
    "# Save imputers/scaler for production\n",
    "joblib.dump(num_imputer, \"num_imputer.joblib\")\n",
    "joblib.dump(scaler, \"scaler.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a0f41fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"loan_paid_back\"\n",
    "ID_COL = \"id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42acd4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 ---\n",
      "Training LightGBM...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'verbose_eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 94\u001b[39m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28mprint\u001b[39m(results)\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m oof_preds_lgb, oof_preds_xgb, results\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m oof_lgb, oof_xgb, cv_results = \u001b[43mcv_train_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTARGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mcv_train_models\u001b[39m\u001b[34m(data, features, target, n_splits, seed)\u001b[39m\n\u001b[32m     21\u001b[39m lgb_params = {\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmetric\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mauc\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mn_jobs\u001b[39m\u001b[33m\"\u001b[39m: -\u001b[32m1\u001b[39m,\n\u001b[32m     31\u001b[39m }\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining LightGBM...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m lgb_model = \u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlgb_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mlgb_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlgb_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlgb_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m lgb_pred = lgb_model.predict(X_val, num_iteration=lgb_model.best_iteration)\n\u001b[32m     41\u001b[39m oof_preds_lgb[val_idx] = lgb_pred\n",
      "\u001b[31mTypeError\u001b[39m: train() got an unexpected keyword argument 'verbose_eval'"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 7) Cross-validated training and evaluation function\n",
    "# ---------------------------\n",
    "def cv_train_models(data, features, target, n_splits=5, seed=RANDOM_STATE):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    oof_preds_lgb = np.zeros(data.shape[0])\n",
    "    oof_preds_xgb = np.zeros(data.shape[0])\n",
    "    metrics = {'lgb': [], 'xgb': []}\n",
    "    fold = 0\n",
    "\n",
    "    for train_idx, val_idx in skf.split(data, data[target]):\n",
    "        fold += 1\n",
    "        print(f\"\\n--- Fold {fold} ---\")\n",
    "        X_tr, X_val = data.iloc[train_idx][features], data.iloc[val_idx][features]\n",
    "        y_tr, y_val = data.iloc[train_idx][target], data.iloc[val_idx][target]\n",
    "\n",
    "        # LightGBM dataset\n",
    "        lgb_train = lgb.Dataset(X_tr, label=y_tr)\n",
    "        lgb_val = lgb.Dataset(X_val, label=y_val, reference=lgb_train)\n",
    "\n",
    "        lgb_params = {\n",
    "            \"objective\": \"binary\",\n",
    "            \"metric\": \"auc\",\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"num_leaves\": 31,\n",
    "            \"max_depth\": -1,\n",
    "            \"seed\": RANDOM_STATE,\n",
    "            \"verbosity\": -1,\n",
    "            \"n_jobs\": -1,\n",
    "        }\n",
    "\n",
    "        print(\"Training LightGBM...\")\n",
    "        lgb_model = lgb.train(\n",
    "            params=lgb_params,\n",
    "            train_set=lgb_train,\n",
    "            num_boost_round=5000,\n",
    "            valid_sets=[lgb_train, lgb_val],\n",
    "            callbacks=[lgb.log_evaluation(period=200)]\n",
    ")\n",
    "\n",
    "        lgb_pred = lgb_model.predict(X_val, num_iteration=lgb_model.best_iteration)\n",
    "        oof_preds_lgb[val_idx] = lgb_pred\n",
    "\n",
    "        # XGBoost\n",
    "        xgb_params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'eta': 0.05,\n",
    "            'max_depth': 6,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'seed': RANDOM_STATE,\n",
    "            'verbosity': 0,\n",
    "        }\n",
    "\n",
    "        print(\"Training XGBoost...\")\n",
    "        dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "        dval = xgb.DMatrix(X_val, label=y_val)\n",
    "        xgb_model = xgb.train(params=xgb_params,\n",
    "                              dtrain=dtrain,\n",
    "                              num_boost_round=5000,\n",
    "                              evals=[(dtrain, 'train'), (dval, 'valid')],\n",
    "                              early_stopping_rounds=100,\n",
    "                              verbose_eval=200)\n",
    "\n",
    "        xgb_pred = xgb_model.predict(xgb.DMatrix(X_val), ntree_limit=xgb_model.best_ntree_limit)\n",
    "        oof_preds_xgb[val_idx] = xgb_pred\n",
    "\n",
    "        # Metrics per fold\n",
    "        for name, preds in [('lgb', lgb_pred), ('xgb', xgb_pred)]:\n",
    "            auc = roc_auc_score(y_val, preds)\n",
    "            pr_auc = average_precision_score(y_val, preds)\n",
    "            pred_labels = (preds >= 0.5).astype(int)\n",
    "            acc = accuracy_score(y_val, pred_labels)\n",
    "            prec = precision_score(y_val, pred_labels, zero_division=0)\n",
    "            rec = recall_score(y_val, pred_labels, zero_division=0)\n",
    "            f1 = f1_score(y_val, pred_labels, zero_division=0)\n",
    "            metrics[name].append({'auc':auc, 'pr_auc':pr_auc, 'accuracy':acc, 'precision':prec, 'recall':rec, 'f1':f1})\n",
    "            print(f\"{name.upper()} Fold {fold} — AUC: {auc:.4f}, PR-AUC: {pr_auc:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "        # Save per-fold models if desired\n",
    "        joblib.dump(lgb_model, f\"lgb_model_fold{fold}.pkl\")\n",
    "        xgb_model.save_model(f\"xgb_model_fold{fold}.json\")\n",
    "\n",
    "    # Aggregate metrics\n",
    "    import statistics\n",
    "    results = {}\n",
    "    for m in metrics:\n",
    "        results[m] = {k: np.mean([fold_m[k] for fold_m in metrics[m]]) for k in metrics[m][0].keys()}\n",
    "    print(\"\\nCross-validated results:\")\n",
    "    print(results)\n",
    "\n",
    "    return oof_preds_lgb, oof_preds_xgb, results\n",
    "\n",
    "oof_lgb, oof_xgb, cv_results = cv_train_models(df, features, TARGET, n_splits=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
